"""
–§–∞—Å–∞–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini AI
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
–°–æ–±–ª—é–¥–∞–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã SOLID
"""

import hashlib
from typing import Dict, List, Optional, TYPE_CHECKING

from loguru import logger

if TYPE_CHECKING:
    from typing import Type

from bot.config import settings
from bot.services.ai_response_generator import AIResponseGenerator
from bot.services.ai_context_manager import AIContextManager
from bot.services.cache_service import AIResponseCache, cache_service
from bot.services.moderation_service import ContentModerationService


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ai_service = None


def get_ai_service() -> "GeminiAIService":
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ AI —Å–µ—Ä–≤–∏—Å–∞"""
    global ai_service
    if ai_service is None:
        ai_service = GeminiAIService()
    return ai_service


class GeminiAIService:
    """
    –§–∞—Å–∞–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini AI
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI —Å–µ—Ä–≤–∏—Å–∞"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
        self.response_generator = AIResponseGenerator()
        self.context_manager = AIContextManager()
        self.moderation = ContentModerationService()

        logger.info("‚úÖ Gemini AI Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def generate_response(
        self,
        user_message: str,
        chat_history: List[Dict[str, str]] = None,
        user_age: Optional[int] = None,
        user_grade: Optional[int] = None,
        user_telegram_id: int = 0,
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ AI —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–∑—Ä–∞—Å—Ç–∞
        """
        try:
            # –ú–æ–¥–µ—Ä–∞—Ü–∏—è –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            is_safe, reason = self.moderation.is_safe_content(user_message)
            if not is_safe:
                logger.warning(f"üö´ –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {reason}")
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å."

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
            cache_key = self._generate_cache_key(user_message, user_age, user_grade)
            cached_response = await cache_service.get(cache_key)
            if cached_response:
                logger.info("üì¶ –û—Ç–≤–µ—Ç –Ω–∞–π–¥–µ–Ω –≤ –∫—ç—à–µ")
                return cached_response

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ response_generator)
            self.context_manager.prepare_context(
                user_message, chat_history, user_age, user_grade
            )

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            ai_response = await self.response_generator.generate_text_response(
                user_message, chat_history
            )

            # –ú–æ–¥–µ—Ä–∞—Ü–∏—è –∏—Å—Ö–æ–¥—è—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
            is_safe_response, reason_response = self.moderation.is_safe_content(ai_response)
            if not is_safe_response:
                logger.warning(f"üö´ –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ—Ç–≤–µ—Ç AI: {reason_response}")
                ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
            await cache_service.set(cache_key, ai_response, ttl=3600)

            logger.info(f"‚úÖ AI –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤")
            return ai_response

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI: {e}")
            return "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –Ω–∞–ø–∏—à–∏ /start"

    async def analyze_image(self, image_data: bytes, prompt: str = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ") -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Gemini Vision API
        """
        try:
            # –ú–æ–¥–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞
            is_safe, reason = self.moderation.is_safe_content(prompt)
            if not is_safe:
                logger.warning(f"üö´ –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {reason}")
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–∞–∫–∏–º –∑–∞–ø—Ä–æ—Å–æ–º."

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            response = await self.response_generator.generate_image_response(image_data, prompt)

            # –ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            is_safe_response, _ = self.moderation.is_safe_content(response)
            if not is_safe_response:
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."

            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω")
            return response

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."

    def _generate_cache_key(
        self, user_message: str, user_age: Optional[int], user_grade: Optional[int]
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        key_data = f"{user_message}:{user_age}:{user_grade}"
        return hashlib.md5(key_data.encode()).hexdigest()

    def get_model_info(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        return {
            "model": settings.gemini_model,
            "temperature": str(settings.ai_temperature),
            "max_tokens": str(settings.ai_max_tokens),
            "public_name": "PandaPalAI"
        }

    def get_service_status(self) -> Dict[str, any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–∏—Å–∞"""
        return {
            "service": "GeminiAIService",
            "status": "healthy",
            "components": {
                "response_generator": "active",
                "context_manager": "active",
                "moderation": "active",
            },
        }
