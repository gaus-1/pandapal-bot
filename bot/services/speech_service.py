"""
–°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI Whisper
–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç
"""

import os
import tempfile
from typing import Optional

import whisper
from loguru import logger


class SpeechRecognitionService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Whisper
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫–∏
    """
    
    def __init__(self, model_size: str = "base"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        
        Args:
            model_size: –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Whisper
                - tiny (39M, –±—ã—Å—Ç—Ä–æ, –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
                - base (74M, –±–∞–ª–∞–Ω—Å) ‚úÖ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
                - small (244M, —Ç–æ—á–Ω–µ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
                - medium (769M, –æ—á–µ–Ω—å —Ç–æ—á–Ω–æ, –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ)
                - large (1550M, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
                - turbo (809M, –±—ã—Å—Ç—Ä–æ, —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
        
        –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: turbo –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫!
        –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ base –∏–ª–∏ small.
        """
        logger.info(f"üé§ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏: {model_size}")
        
        try:
            self.model = whisper.load_model(model_size)
            self.model_size = model_size
            logger.info(f"‚úÖ Whisper –º–æ–¥–µ–ª—å {model_size} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
            raise
    
    async def transcribe_voice(
        self, 
        voice_file_bytes: bytes, 
        language: str = "ru",
        auto_detect_language: bool = True
    ) -> Optional[str]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            voice_file_bytes: –ë–∞–π—Ç—ã –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ (.ogg)
            language: –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —è–∑—ã–∫ (ru/en) - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ auto_detect=False
            auto_detect_language: –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        
        Returns:
            str: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        temp_file_path = None
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=".ogg"
            ) as temp_file:
                temp_file.write(voice_file_bytes)
                temp_file_path = temp_file.name
            
            logger.info(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏: {temp_file_path}")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            transcribe_options = {
                "fp16": False,  # CPU —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
                "verbose": False
            }
            
            # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ
            if not auto_detect_language:
                transcribe_options["language"] = language
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å —á–µ—Ä–µ–∑ Whisper
            result = self.model.transcribe(temp_file_path, **transcribe_options)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —è–∑—ã–∫
            detected_lang = result.get("language", "unknown")
            logger.info(f"üåç –û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {detected_lang}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            text = result["text"].strip()
            
            logger.info(f"‚úÖ –†–µ—á—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞: {text[:100]}...")
            
            return text
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {e}")
            return None
            
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")
    
    def get_service_status(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞"""
        return {
            "service": "SpeechRecognitionService",
            "status": "active" if self.model else "inactive",
            "model": "whisper-base",
            "languages": ["ru", "en"]
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ (Singleton)
_speech_service: Optional[SpeechRecognitionService] = None


def get_speech_service() -> SpeechRecognitionService:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
    –°–æ–∑–¥–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ
    """
    global _speech_service
    
    if _speech_service is None:
        _speech_service = SpeechRecognitionService(model_size="base")
    
    return _speech_service

