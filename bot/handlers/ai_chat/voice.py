"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∏ –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è AI —á–∞—Ç–∞.

FSM: –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ AI.
"""

from aiogram import F, Router
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup, Message
from loguru import logger

from bot.monitoring import log_user_activity

from .helpers import check_premium_limit, read_file_safely
from .text import handle_ai_message

MAX_AUDIO_SIZE = 20 * 1024 * 1024  # 20MB


class VoiceConfirmState(StatesGroup):
    """–°–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞."""

    waiting_for_confirm = State()
    waiting_for_correction = State()


def register_handlers(router: Router) -> None:
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç handlers –¥–ª—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∏ –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–π."""
    router.message.register(handle_voice, F.voice)
    router.message.register(handle_audio, F.audio)
    router.callback_query.register(handle_voice_confirm_callback, F.data == "voice_confirm")
    router.callback_query.register(handle_voice_edit_callback, F.data == "voice_edit")
    router.message.register(
        handle_voice_correction_text, VoiceConfirmState.waiting_for_correction, F.text
    )


async def _process_audio_input(
    message: Message, file_id: str, media_type: str, state: FSMContext | None = None
) -> None:
    """
    –û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö/–∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–π.

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        file_id: ID —Ñ–∞–π–ª–∞ –≤ Telegram
        media_type: "voice" –∏–ª–∏ "audio" (–¥–ª—è –ª–æ–≥–æ–≤ –∏ UI)
    """
    telegram_id = message.from_user.id
    emoji = "üé§" if media_type == "voice" else "üéµ"
    label = "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ" if media_type == "voice" else "–ê—É–¥–∏–æ—Ñ–∞–π–ª"
    activity_prefix = "voice" if media_type == "voice" else "audio"

    try:
        logger.info(f"{emoji} –ü–æ–ª—É—á–µ–Ω {media_type} –æ—Ç {telegram_id}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Premium-–ª–∏–º–∏—Ç–æ–≤ –î–û —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        if not await check_premium_limit(telegram_id, message.from_user.username, message):
            return

        processing_msg = await message.answer(
            f"{emoji} –°–ª—É—à–∞—é {label.lower()}... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏! üêº"
        )

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        tg_file = await message.bot.get_file(file_id)
        file_stream = await message.bot.download_file(tg_file.file_path)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
        if tg_file.file_size and tg_file.file_size > MAX_AUDIO_SIZE:
            await processing_msg.edit_text(
                f"{emoji} {label} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! "
                f"–ú–∞–∫—Å–∏–º—É–º {MAX_AUDIO_SIZE / (1024 * 1024):.0f}MB. "
                f"–ü–æ–ø—Ä–æ–±—É–π –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ! üìè"
            )
            return

        # –ß–∏—Ç–∞–µ–º –±–∞–π—Ç—ã –ø–æ—Ç–æ–∫–æ–≤–æ
        try:
            audio_data = read_file_safely(file_stream, max_size=MAX_AUDIO_SIZE)
        except ValueError as e:
            logger.warning(f"‚ö†Ô∏è {label} –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç: {e}")
            await processing_msg.edit_text(
                f"{emoji} {label} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! –ü–æ–ø—Ä–æ–±—É–π –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ! üìè"
            )
            return

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
        from bot.services.speech_service import get_speech_service

        speech_service = get_speech_service()
        lang_code = (message.from_user.language_code or "ru").strip().lower()
        speech_lang = "en" if lang_code.startswith("en") else "ru"
        recognized_text = await speech_service.transcribe_voice(audio_data, language=speech_lang)

        if not recognized_text:
            await processing_msg.edit_text(
                f"{emoji} –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\n"
                "–ü–æ–ø—Ä–æ–±—É–π –≥–æ–≤–æ—Ä–∏—Ç—å —á–µ—Ç—á–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º! üìù"
            )
            log_user_activity(
                telegram_id, f"{activity_prefix}_recognition_failed", False, "SpeechKit failed"
            )
            return

        await processing_msg.delete()

        # –ü–µ—Ä–µ–≤–æ–¥ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
        from bot.services.translate_service import get_translate_service

        translate_service = get_translate_service()
        detected_lang = await translate_service.detect_language(recognized_text)

        display_text = f'–Ø —É—Å–ª—ã—à–∞–ª: "{recognized_text}"'
        if (
            detected_lang
            and detected_lang != "ru"
            and detected_lang in translate_service.SUPPORTED_LANGUAGES
        ):
            lang_name = translate_service.get_language_name(detected_lang)
            logger.info(f"üåç {media_type}: –û–±–Ω–∞—Ä—É–∂–µ–Ω –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–π —è–∑—ã–∫: {detected_lang}")

            translated_text = await translate_service.translate_text(
                recognized_text, target_language="ru", source_language=detected_lang
            )
            if translated_text:
                display_text = (
                    f'–Ø —É—Å–ª—ã—à–∞–ª –Ω–∞ {lang_name}: "{recognized_text}"\n'
                    f'üá∑üá∫ –ü–µ—Ä–µ–≤–æ–¥: "{translated_text}"'
                )
                recognized_text = (
                    f"üåç –í–∏–∂—É, —á—Ç–æ —Ç—ã —Å–∫–∞–∑–∞–ª –Ω–∞ {lang_name}!\n\n"
                    f"üìù –û—Ä–∏–≥–∏–Ω–∞–ª: {recognized_text}\n"
                    f"üá∑üá∫ –ü–µ—Ä–µ–≤–æ–¥: {translated_text}\n\n"
                    f"–û–±—ä—è—Å–Ω–∏ —ç—Ç–æ—Ç –ø–µ—Ä–µ–≤–æ–¥ –∏ –ø–æ–º–æ–≥–∏ –ø–æ–Ω—è—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞."
                )
                logger.info(f"‚úÖ {media_type} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {detected_lang} ‚Üí ru")
            else:
                display_text = f'–Ø —É—Å–ª—ã—à–∞–ª: "{recognized_text}"'

        logger.info(f"‚úÖ –†–µ—á—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞: {recognized_text[:100]}")
        log_user_activity(telegram_id, f"{activity_prefix}_message_sent", True)

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: inline-–∫–Ω–æ–ø–∫–∏ ¬´–û—Ç–ø—Ä–∞–≤–∏—Ç—å¬ª / ¬´–ò—Å–ø—Ä–∞–≤–∏—Ç—å¬ª
        confirm_keyboard = InlineKeyboardMarkup(
            inline_keyboard=[
                [
                    InlineKeyboardButton(text="‚úÖ –û—Ç–ø—Ä–∞–≤–∏—Ç—å", callback_data="voice_confirm"),
                    InlineKeyboardButton(text="‚úèÔ∏è –ò—Å–ø—Ä–∞–≤–∏—Ç—å", callback_data="voice_edit"),
                ]
            ]
        )
        await message.answer(
            f"{emoji} <i>{display_text}</i>\n\n–ü–æ–¥—Ç–≤–µ—Ä–¥–∏ –∏–ª–∏ –∏—Å–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç:",
            reply_markup=confirm_keyboard,
            parse_mode="HTML",
        )
        if state:
            await state.set_state(VoiceConfirmState.waiting_for_confirm)
            await state.update_data(recognized_text=recognized_text)
        else:
            # –ë–µ–∑ FSM ‚Äî —Å—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ AI (fallback –¥–ª—è webhook –±–µ–∑ state)
            original_text = message.text
            try:
                object.__setattr__(message, "text", recognized_text)
                await handle_ai_message(message, None)
            finally:
                if original_text is not None:
                    object.__setattr__(message, "text", original_text)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {media_type}: {e}")
        await message.answer(
            f"üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {label.lower()}.\n–ü–æ–ø—Ä–æ–±—É–π –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º! üìù"
        )
        log_user_activity(telegram_id, f"{activity_prefix}_processing_error", False, str(e))


async def handle_voice(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    await _process_audio_input(message, message.voice.file_id, "voice", state)


async def handle_audio(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤."""
    await _process_audio_input(message, message.audio.file_id, "audio", state)


async def handle_voice_confirm_callback(callback: CallbackQuery, state: FSMContext) -> None:
    """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ AI."""
    await callback.answer()
    data = await state.get_data()
    recognized_text = data.get("recognized_text")
    await state.clear()
    if not recognized_text:
        await callback.message.answer("‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø–∏—à–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ –∑–∞–Ω–æ–≤–æ.")
        return
    logger.info(f"‚úÖ STT –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω: {recognized_text[:80]}...")
    message = callback.message
    original_text = message.text
    try:
        object.__setattr__(message, "text", recognized_text)
        object.__setattr__(message, "from_user", callback.from_user)
        await handle_ai_message(message, state)
    finally:
        if original_text is not None:
            object.__setattr__(message, "text", original_text)


async def handle_voice_edit_callback(callback: CallbackQuery, state: FSMContext) -> None:
    """–ò—Å–ø—Ä–∞–≤–∏—Ç—å: –∂–¥—ë–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º."""
    await callback.answer()
    await state.set_state(VoiceConfirmState.waiting_for_correction)
    await callback.message.answer("‚úèÔ∏è –ù–∞–ø–∏—à–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–º:")


async def handle_voice_correction_text(message: Message, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    correction = (message.text or "").strip()
    await state.clear()
    if not correction:
        await message.answer("‚ùå –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ù–∞–ø–∏—à–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–º.")
        return
    logger.info(f"‚úÖ STT –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {correction[:80]}...")
    original_text = message.text
    try:
        object.__setattr__(message, "text", correction)
        await handle_ai_message(message, state)
    finally:
        if original_text is not None:
            object.__setattr__(message, "text", original_text)
